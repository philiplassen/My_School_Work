#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Mar 12 15:54:01 2019

@author: luise
"""

"""
###############################################################################
All functions used in the 6th Assignment
###############################################################################
"""

#import packages
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from skimage import feature
from scipy.fftpack import fft2, fftshift, ifft2, ifftshift
from scipy import signal
from scipy.ndimage import rotate
from skimage.feature import peak_local_max



def local_maxima(img, sigma = 1, method = 'k', min_distance = 1):
  """
  finds local maxima in the feature map generated by the 
  skimage.feature.corner_harris function (edge detection)
  """
  return(feature.corner_peaks(feature.corner_harris(img, sigma = sigma, method = method), min_distance = min_distance))



def Gaussian_kernel(x_max, y_max, sigma):
  """
  computes an image of a discrete Gaussian distribution
  INPUT:
    - x_max, y_max: maximal x-/y-value
    - sigma: standartd derivation
  OUTPUT:
    - gauss: normalized Gaussian image of the size (2*x_max + 1, 2*y_max + 1)
  """
  x = np.arange(-x_max, x_max + 1)
  y = np.arange(-y_max, y_max + 1)
  xx, yy = np.meshgrid(x, y)
  gauss = 1/(2.*np.pi*sigma**2)*np.exp(-(xx**2 + yy**2) / (2. * sigma**2))
  #summe = np.sum(gauss)
  return(gauss)


def d2x_Gaussian_kernel(x_len, y_len, tau):
  """
  computes the second derivative of a descrete Gaussian in respect to x
  INPUT:
    - x_len, y_len: size of the kernel
    - tau: standartd derivation
  OUTPUT:
    - d2gauss: normalized Gaussian image of the size (2*x_max + 1, 2*y_max + 1)
  """
  x = np.arange(-np.ceil(x_len/2), np.ceil(x_len/2))
  y = np.arange(-np.ceil(y_len/2), np.ceil(y_len/2))
  xx, yy = np.meshgrid(x, y)
  gauss = 1/(2.*np.pi*tau**2)*np.exp(-(xx**2 + yy**2) / (2. * tau**2))
  d2gauss = 1/tau**2 * (xx**2/tau**2 -1) * gauss
  #summe = np.sum(gauss)
  return(d2gauss)
def d2y_Gaussian_kernel(x_len, y_len, tau):
  """
  computes the second derivative of a descrete Gaussian in respect to y
  INPUT:
    - x_len, y_len: size of the kernel
    - tau: standartd derivation
  OUTPUT:
    - d2gauss: normalized Gaussian image of the size (2*x_max + 1, 2*y_max + 1)
  """
  x = np.arange(-np.ceil(x_len/2), np.ceil(x_len/2))
  y = np.arange(-np.ceil(y_len/2), np.ceil(y_len/2))
  xx, yy = np.meshgrid(x, y)
  gauss = 1/(2.*np.pi*tau**2)*np.exp(-(xx**2 + yy**2) / (2. * tau**2))
  d2gauss = 1/tau**2 * (yy**2/tau**2 -1) * gauss
  #summe = np.sum(gauss)
  return(d2gauss)



def scale(img, sigma):
  """
  Convolution with an image and an Gaussian kernel with std = sigma
  INPUT:
    - img: gray scaled image
    - sigma: standart derivation
  OUTPUT:
    - img_filter: filtered image
  """
  
  size = img.shape
  img_filter = np.copy(img)
  #computing the gaussian kernel
  kernel = Gaussian_kernel(size[1]//2, size[0]//2, sigma)

  #convolution by convertion into frequency domain
  #fourier transformation
  img_filter_fft = fft2(img_filter)
  kernel_fft = fft2(kernel)#, size)
  #convolution in fourier domain = multiplication
  img_filter_fft = img_filter_fft*kernel_fft
  #transform it back
  img_filter = ifft2(img_filter_fft)
  
  return(np.absolute(fftshift(img_filter)))
def H(I, tau):
  """
  computes the scale space applied to the image I with scale tau
  INPUT:
    - I: image
    - tau: scale factor for blob recocnition
  OUTPUT:
    - H_img: scale space of I
  """
  y, x = I.shape
  #compute the second derivative of the Gaussian blob image

def H00(tau, sigma):
  return(-2*tau**2/(sigma**2+tau**2) * 1/(2*np.pi*(sigma**2 + tau**2)))

def dH00(tau, sigma):
  return(2*(tau**3-sigma**2*tau)/np.pi*(sigma**2 + tau**2)**3)


def H(I, tau):
  """
  computes the scale space applied to the image I with scale tau
  INPUT:
    - I: image
    - tau: scale factor for blob recocnition
  OUTPUT:
    - H_img: scale space of I
  """
  y, x = I.shape
  #compute the second derivative of the Gaussian blob image
def convolve(I1, I2):
  """
  convolution of two images by converting them to the Fourier space
  INPUT:
    - I1, I2: image 1 and 2
  OUTPUT:
    - I_conv
  """
  I1_fft = fft2(I1)
  I2_fft = fft2(I2)
  I_conv_fft = I1_fft * I2_fft
  I_conv = np.absolute(ifft2(I_conv_fft))
  return(I_conv)
  
  d2Gx = d2x_Gaussian_kernel(6*tau, 6*tau, tau)
  d2Gy = d2y_Gaussian_kernel(6*tau, 6*tau, tau)
  #compute H as the sum of two convolutions
  x_conv = signal.convolve2d(I, d2Gx, mode='same')#, boundary='symm')
  y_conv = signal.convolve2d(I, d2Gy, mode='same')#, boundary='symm')
  H_img = tau**2 * (x_conv + y_conv)
  return(H_img)


def J_multitau(I, tau):
  y, x = I.shape
  H_img = np.zeros((y, x, len(tau)))
  dummy = 0
  #computing H for eac tau value
  for t in tau:
    #compute the second derivative of the Gaussian blob image
    d2Gx = d2x_Gaussian_kernel(6*t, 6*t, t)
    d2Gy = d2y_Gaussian_kernel(6*t, 6*t, t)
    


def H_multitau(I, tau):
  """
  computes the scale space applied to the image I for several tau values. It 
  returns the maximal H value for every tau at the pixel location x, y
  INPUT:
    - I: image
    - tau: scale factor array for blob recocnition
  OUTPUT:
    - H_img: scale space of I with the max values at each location
    - ind: index map of the corresponding max tau
  """
  y, x = I.shape
  H_img = np.zeros((y, x, len(tau)))
  dummy = 0
  #computing H for eac tau value
  for t in tau:
    #compute the second derivative of the Gaussian blob image
    d2Gx = d2x_Gaussian_kernel(6*t, 6*t, t)
    d2Gy = d2y_Gaussian_kernel(6*t, 6*t, t)
    #compute H as the sum of two convolutions 
    x_conv = signal.convolve2d(I, d2Gx, mode='same')#, boundary='symm')
    y_conv = signal.convolve2d(I, d2Gy, mode='same')#, boundary='symm')
    H_img[:, :, dummy] = t**2 * (x_conv + y_conv)
    dummy += 1
    print('finished %i' %t)
  #computing the max value
  H_img_max = np.max(H_img, axis=2)
  ind = np.argmax(H_img, axis=2)
  #return(np.absolute(H_img_max), ind)
  return(H_img_max, ind)




def H_fft(I, tau):
  """
  computes WHAT?!
  INPUT:
    - I: image
    - tau: scale factor for blob recocnition
  OUTPUT:
    - H_img: 
  """
  y, x = I.shape
  #compute the second derivative of the Gaussian blob image
  d2Gx = d2x_Gaussian_kernel(x, y, tau)
  d2Gy = d2y_Gaussian_kernel(x, y, tau)
  #compute H as the sum of two convolutions
  x_conv = convolve(I, d2Gx)#, boundary='symm', mode='same')
  y_conv = convolve(I, d2Gy)#, boundary='symm', mode='same')
  H_img = tau**2 * (x_conv + y_conv)
  return(np.absolute(H_img))



def find_max(H_img, n = 20):
  """
  finds the n highest pixel in the image
  INPUT:
    - H_img: image
    - n: number of max values
  OUTPUT:
    - maximal: max values
    - minimal: min values
  """
  maximal = np.zeros((n, 2))
  minimal = np.zeros((n, 2))
  m_val = np.median(H_img)
  for i in range(n):
    ind_max = np.unravel_index(np.argmax(H_img, axis=None), H_img.shape)
    maximal[i] = ind_max
    H_img[ind_max] = m_val

    ind_min = np.unravel_index(np.argmin(H_img, axis=None), H_img.shape)
    minimal[i] = ind_min
    H_img[ind_min] = m_val
    
  return(maximal, minimal)
  
  
def find_local_max(H_img, n = 20, k = 1):
  """
  finds the n highest local maxima in the image
  INPUT:
    - H_img: image
    - n: number of max values
    - k: minimal distance between the peeks
  OUTPUT:
    - maximal: max values
    - minimal: min values
  """
  local_max_coords = peak_local_max(H_img, min_distance=k, exclude_border = True)
  local_max = [H_img[local_max_coords[0, 0], local_max_coords[0, 1]]]
  for m in range(1, len(local_max_coords)):
    local_max.append(H_img[local_max_coords[m, 0], local_max_coords[m, 1]])
  
  maximal = np.zeros((len(local_max), 3))
  maximal[:, 0:2] = local_max_coords
  maximal[:, 2] = local_max
  maximal = maximal[maximal[:,2].argsort()]

  local_min_coords = peak_local_max(-1*H_img, min_distance=k, exclude_border = True)
  local_min = [H_img[local_min_coords[0, 0], local_min_coords[0, 1]]]
  for m in range(1, len(local_min_coords)):
    local_min.append(H_img[local_min_coords[m, 0], local_min_coords[m, 1]])
  
  minimal = np.zeros((len(local_min), 3))
  minimal[:, 0:2] = local_min_coords
  minimal[:, 2] = np.absolute(local_min)
  minimal = minimal[minimal[:,2].argsort()]
  
  return(maximal[len(local_max_coords)-n-1:-1], minimal[len(local_max_coords)-n-1:-1])#[:n+1])

    



